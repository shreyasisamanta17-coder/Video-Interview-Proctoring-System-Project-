<!DOCTYPE html>
<html>
<head>
  <title>Interview Screen</title>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/face_detection.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
</head>
<body>
  <h2>Candidate Interview</h2>
  <div id="alertBox" style="color:red; font-weight:bold; margin-top:10px;"></div>

  <!-- video + canvas -->
  <video id="video" autoplay playsinline style="display:none;"></video>
  <canvas id="canvas" width="640" height="480" style="border:1px solid black;"></canvas>
  <br />

  <!-- recording buttons -->
  <button id="startBtn">Start Recording</button>
  <button id="stopBtn">Stop Recording</button>
  <a id="downloadLink" style="display:none;">Download Video</a>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");

    const startBtn = document.getElementById("startBtn");
    const stopBtn = document.getElementById("stopBtn");
    const downloadLink = document.getElementById("downloadLink");
    const alertBox = document.getElementById("alertBox");

    let mediaRecorder;
    let recordedChunks = [];

    // camera + mic access
    navigator.mediaDevices.getUserMedia({ video: true, audio: true })
      .then(stream => {
        video.srcObject = stream;

        mediaRecorder = new MediaRecorder(stream);

        mediaRecorder.ondataavailable = (e) => {
          if (e.data.size > 0) recordedChunks.push(e.data);
        };

        mediaRecorder.onstop = () => {
          const blob = new Blob(recordedChunks, { type: "video/webm" });
          const url = URL.createObjectURL(blob);
          downloadLink.href = url;
          downloadLink.download = "interview_recording.webm";
          downloadLink.style.display = "block";
          downloadLink.textContent = "Download Recording";

          // === backend e send korar jonno ===
          const formData = new FormData();
          formData.append("video", blob, "interview_recording.webm");

          fetch("http://localhost:5000/upload", {
            method: "POST",
            body: formData
          })
          .then(res => res.text())
          .then(msg => console.log("✅ Server response:", msg))
          .catch(err => console.error("❌ Upload failed:", err));
        };

        startBtn.onclick = () => {
          recordedChunks = [];
          mediaRecorder.start();
          console.log("Recording started");
        };

        stopBtn.onclick = () => {
          mediaRecorder.stop();
          console.log("Recording stopped");
        };
      })
      .catch(err => console.error("Error accessing devices:", err));

    // === Face Detection setup ===
    const faceDetection = new FaceDetection({locateFile: (file) => {
      return `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/${file}`;
    }});

    faceDetection.setOptions({
      model: 'short',
      minDetectionConfidence: 0.5
    });

    faceDetection.onResults(onResults);

    async function detectFace() {
      const cameraStream = video.srcObject;
      const videoTrack = cameraStream.getVideoTracks()[0];
      const imageCapture = new ImageCapture(videoTrack);

      async function processFrame() {
        const bitmap = await imageCapture.grabFrame();
        ctx.drawImage(bitmap, 0, 0, canvas.width, canvas.height);
        await faceDetection.send({image: bitmap});
        requestAnimationFrame(processFrame);
      }

      processFrame();
    }

    let noFaceStartTime = null;

    function onResults(results) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      if (!results.detections || results.detections.length === 0) {
        if (!noFaceStartTime) noFaceStartTime = Date.now();
        const elapsed = (Date.now() - noFaceStartTime) / 1000;
        if (elapsed > 10) {
          alertBox.textContent = "⚠️ No face detected for more than 10 seconds!";
          noFaceStartTime = Date.now();
        }
      } else {
        noFaceStartTime = null;
        alertBox.textContent = "";
        results.detections.forEach(detection => {
          drawRectangle(detection);
        });
      }
    }

    function drawRectangle(detection) {
      const box = detection.boundingBox;
      ctx.strokeStyle = "red";
      ctx.lineWidth = 3;
      ctx.strokeRect(
        box.xCenter - box.width/2,
        box.yCenter - box.height/2,
        box.width,
        box.height
      );
    }

    video.onplaying = () => {
      detectFace();
    };
  </script>
</body>
</html>
